---
title: "analyze"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
rm(list = ls())
library(data.table); library(tidyverse); library(correlation)
library(BayesFactor); library(BFpack); library(ggbeeswarm); library(patchwork); library(ggdist)
library(hausekeep)
library(marginaleffects)
library(lme4)
theme_set(theme_minimal())
```

```{r}
d0_feed <- fread("../data/clean/data_feed.csv")

d0_feed <- d0_feed[attention == 1.0 & ipblock == 0]
d0_feed[, .(mean_n_dwells = mean(n_dwells, na.rm = T), mean_dwell = mean(dwell, na.rm = T), mean_ldwell = mean(ldwell, na.rm = T)), by = .(user_id, entity_set, condition)][, .(mean2_n_dwells = mean(mean_n_dwells, na.rm = T), mean2_dwell = mean(mean_dwell, na.rm = T), mean2_ldwell = mean(mean_ldwell, na.rm = T)), keyby = .(condition, entity_set)]
d0_feed[, .(mean_n_dwells = mean(n_dwells, na.rm = T), mean_dwell = mean(dwell, na.rm = T), mean_ldwell = mean(ldwell, na.rm = T)), by = .(user_id, condition)][, .(mean2_n_dwells = mean(mean_n_dwells, na.rm = T), mean2_dwell = mean(mean_dwell, na.rm = T), mean2_ldwell = mean(mean_ldwell, na.rm = T)), keyby = .(condition)]
library(fixest)
feols(ldwell ~ condition, d0_feed[entity_set == 'oct9_news' & dwell>2000], cluster = ~user_id+entity_id)

feols(dwell ~ condition, d0_feed, cluster = ~user_id)
feols(n_dwells ~ condition, d0_feed, cluster = ~user_id)
feglm(n_dwells ~ condition, d0_feed, cluster = ~user_id, family = 'quasipoisson')

hist(d0_feed$ldwell)
hist(d0_feed$dwell)
hist(d0_feed$n_dwells)

d1 <- fread("../data/clean/data.csv")
d1[, n_distinct(user_id), keyby = .(condition)]
d1[, n_distinct(user_id), keyby = .(condition, attention, ipblock)]  # users per condition

d2 <- d1[attention == 1.0 & ipblock == 0]
d2[, n_distinct(user_id), keyby = .(condition, attention, ipblock)]

# remove alphanumeric response column, ip address and country codes
d2 <- select(d2, user_id, condition, field, news_eval)
perc <- d2[field == "willsmith_cards_perc", .(user_id, news_eval)]
setnames(perc, c("user_id", "willsmith_perc"))
perc

d2 <- d2[field != "willsmith_cards_perc"] |> left_join(perc) 
setDT(d2)
```

```{r}
d2 <- separate(d2, field, c("topic", "question"), "_")
d3 <- dcast(d2, user_id + condition + topic + willsmith_perc ~ question, value.var = "news_eval")
d3[, rating_combined := (importance + newsworthiness) / 2]
d3
fwrite(d3, "../data/clean/data_model.csv")
```

```{r check correlations}
cors <- d3[, .(r = cor(importance, newsworthiness)), topic]
cors
ggplot(d3, aes(importance, newsworthiness)) +
    facet_wrap(~ topic) +
    geom_jitter() +
    geom_smooth(method = 'lm', alpha = 0.1) 

select(d3, topic, importance, newsworthiness) %>% group_by(topic) %>% correlation()
```


```{r}
d4 <- distinct(d3[, .(user_id, condition, willsmith_perc)])
d4[, condition := condition + 0.5]
summary(lm(willsmith_perc ~ condition, d4))

p1 <- ggplot(d4, aes(factor(condition, labels = c("control", "treatment")), willsmith_perc)) +
    geom_quasirandom(alpha = 0.3, size = 0.8) +
    stat_summary(fun = mean, geom = 'point', shape = 95, size = 6) +
    stat_summary(fun.data = mean_cl_normal, geom = 'errorbar', width = 0, size = 1.1) +
    scale_y_continuous(limits = c(0, 100)) +
    labs(x = "", y = "self-reported percent will smith cards seen")
p1

# ggsave("../figures/manipulation_check.png", p1, dpi = 300, width = 5, height = 5, bg = "white")
```


```{r fit models}

# if cor is < 0.7 interpret this
ttestBF(formula = importance ~ condition, data = d3[topic == "willsmith"])
m1_imp <- lm(importance ~ condition, d3[topic == "willsmith"])
summary(m1_imp)
m1_impbf <- BF(m1_imp, hypothesis = "condition = 0")
summary(m1_impbf)

ttestBF(formula = newsworthiness ~ condition, data = d3[topic == "willsmith"])
m1_newsw <- lm(newsworthiness ~ condition, d3[topic == "willsmith"])
summary(m1_newsw)
m1_newswbf <- BF(m1_newsw, hypothesis = "condition = 0")
summary(m1_newswbf)

# if cor > 0.7, interpret this
ttestBF(formula = rating_combined ~ condition, data = d3[topic == "willsmith"])
m1_combine <- lm(rating_combined ~ condition, d3[topic == "willsmith"])
summary(m1_combine)
m1_combinebf <- BF(m1_combine, hypothesis = "condition = 0")
summary(m1_combinebf)
```


```{r}

#compute bayes factor of 20 ppl
#then loop to add 1 person at a time, to compute bayes factor at each itertn
# do till last subject, get N-20 bayes factors, save p values
# might hit 0.1 or 10 at some pt in middle
# plot bayes factors as function of iteration
# correlate p vals and bayes factors - sign or not?, no corr if there is no effect

#n, bf1, pval1, bf2, pval2 - do for importance
library(stringr)
BFs <- {}
Ns <- {}
Ps <- {}

for (i in 20:nrow(d3[topic == "willsmith"])) {
  testOutput <- ttestBF(formula = importance ~ condition, data = d3[topic == "willsmith"][1:i,])
  m1_imp <- lm(importance ~ condition, d3[topic == "willsmith"][1:i,])
  m1_imp_testOutput <- summaryh(m1_imp)
  res <- str_match(m1_imp_testOutput[term == "condition"]$results, "p = \\s*(.*?)\\s*,")
  BFs <- append(BFs, testOutput@bayesFactor[["bf"]])
  Ns <- append(Ns, i)
  Ps <- append(Ps, res[,2])
}

png("../figures/BF_history_imp.png")
plot(Ns, exp(BFs))
dev.off()

png("../figures/P_history_imp.png")
plot(Ns, Ps)
dev.off()

png("../figures/P_BF_corr_imp.png")
plot(exp(BFs), Ps)
text(paste("Correlation:", cor(exp(BFs), as.numeric(Ps), method = "pearson")), x = 0.5, y = 0.5)
dev.off()



BFs <- {}
Ns <- {}
Ps <- {}

for (i in 20:nrow(d3[topic == "willsmith"])) {
  testOutput <- ttestBF(formula = newsworthiness ~ condition, data = d3[topic == "willsmith"][1:i,])
  m1_newsw <- lm(newsworthiness ~ condition, d3[topic == "willsmith"][1:i,])
  m1_newsw_testOutput <- summaryh(m1_newsw)
  res <- str_match(m1_newsw_testOutput[term == "condition"]$results, "p = \\s*(.*?)\\s*,")
  BFs <- append(BFs, testOutput@bayesFactor[["bf"]])
  Ns <- append(Ns, i)
  Ps <- append(Ps, res[,2])
}

png("../figures/BF_history_newsw.png")
plot(Ns, exp(BFs))
dev.off()

png("../figures/P_history_newsw.png")
plot(Ns, Ps)
dev.off()

png("../figures/P_BF_corr_newsw.png")
plot(exp(BFs), Ps)
text(paste("Correlation:", cor(exp(BFs), as.numeric(Ps), method = "pearson")), x = 15, y = 0.05)
dev.off()


```


```{r fit models after filtering subjects}

d3a <- d3[(condition == -0.5 & willsmith_perc < 20) | (condition == 0.5 & willsmith_perc > 33)]
d3a[, fivenum(willsmith_perc), condition]
d3a[, n_distinct(user_id), condition]
user_subset <- d3a[, unique(user_id)]

# if cor is < 0.7 interpret this
ttestBF(formula = importance ~ condition, data = d3a[topic == "willsmith"])
m1_imp <- lm(importance ~ condition, d3a[topic == "willsmith"])
summary(m1_imp)
m1_impbf <- BF(m1_imp, hypothesis = "condition = 0")
summary(m1_impbf)

ttestBF(formula = newsworthiness ~ condition, data = d3a[topic == "willsmith"])
m1_newsw <- lm(newsworthiness ~ condition, d3a[topic == "willsmith"])
summary(m1_newsw)
m1_newswbf <- BF(m1_newsw, hypothesis = "condition = 0")
summary(m1_newswbf)

# if cor > 0.7, interpret this
ttestBF(formula = rating_combined ~ condition, data = d3a[topic == "willsmith"])
m1_combine <- lm(rating_combined ~ condition, d3a[topic == "willsmith"])
summary(m1_combine)
m1_combinebf <- BF(m1_combine, hypothesis = "condition = 0")
summary(m1_combinebf)
```


```{r}
dodge <- 0.8
p2 <- ggplot(d2, aes(question, news_eval, col = factor(condition, labels = c("control", "treatment")))) +
    facet_wrap(~ topic) +
    geom_quasirandom(alpha = 0.1, dodge = dodge, size = 0.8) +
    stat_summary(fun = mean, geom = 'point', shape = 95, size = 6, position = position_dodge(dodge)) +
    stat_summary(fun.data = mean_cl_normal, geom = 'errorbar', width = 0, size = 1.1, position = position_dodge(dodge)) +
    scale_y_continuous(limits = c(0, 7), breaks = 1:6) +
    labs(x = "", y = "rating", col = "condition")
p2

# ggsave("../figures/main_effect.png", p2, dpi = 300, width = 13, height = 5, bg = "white")
```


```{r interact perc with condition}
d3[, willsmith_percC := willsmith_perc - mean(willsmith_perc, na.rm = T)]
m1 <- lm(importance ~ condition * willsmith_percC, d3[topic == "willsmith"])
summaryh(m1)

m2 <- lm(newsworthiness ~ condition * willsmith_percC, d3[topic == "willsmith"])
summaryh(m2)

m3 <- lm(rating_combined ~ condition * willsmith_percC, d3[topic == "willsmith"])
summaryh(m3)

d3[willsmith_perc %in% c(5, 35), .(willsmith_perc, willsmith_percC)] |> distinct()
marginaleffects(m3, datagrid(willsmith_percC = c(-30.54032, -0.5403226), condition = c(-0.5, 0.5)))

m1 <- lm(importance ~ willsmith_percC, d3[topic == "willsmith"])
summaryh(m1)
m2 <- lm(newsworthiness ~ willsmith_percC, d3[topic == "willsmith"])
summaryh(m2)
m3 <- lm(rating_combined ~ willsmith_percC, d3[topic == "willsmith"])
summaryh(m3)
```


```{r}
dodge <- 0.8
p2 <- ggplot(d2[user_id %in% user_subset], aes(question, news_eval, col = factor(condition, labels = c("control", "treatment")))) +
    facet_wrap(~ topic) +
    geom_quasirandom(alpha = 0.1, dodge = dodge, size = 0.8) +
    stat_summary(fun = mean, geom = 'point', shape = 95, size = 6, position = position_dodge(dodge)) +
    stat_summary(fun.data = mean_cl_normal, geom = 'errorbar', width = 0, size = 1.1, position = position_dodge(dodge)) +
    scale_y_continuous(limits = c(0, 7), breaks = 1:6) +
    labs(x = "", y = "rating", col = "condition")
p2

# ggsave("../figures/main_effect_subset.png", p2, dpi = 300, width = 13, height = 5, bg = "white")
```











```{r}
dodge <- 0.8
ggplot(d2, aes(question, news_eval, fill = factor(condition, labels = c("control", "treatment")))) +
    facet_wrap(~ topic) +
    stat_slab(aes(thickness = stat(pdf*n)), scale = 0.5, position = position_dodge(dodge), alpha = 0.3) +
    # geom_quasirandom(alpha = 0.1, dodge = dodge, size = 0.3) +
    geom_jitter(position = position_jitterdodge(jitter.width = 0.1, dodge.width = dodge, jitter.height = 0.1), size = 0.3, alpha = 0.1) +
    # stat_dotsinterval(side = "left", scale = 0.2, position = position_dodge(dodge)) +
    stat_summary(fun = mean, geom = 'point', shape = 95, size = 6, position = position_dodge(dodge), aes(col = factor(condition, labels = c("control", "treatment")))) +
    stat_summary(fun.data = mean_cl_normal, geom = 'errorbar', width = 0, size = 1.1, position = position_dodge(dodge), aes(col = factor(condition, labels = c("control", "treatment")))) +
    scale_y_continuous(limits = c(0, 7), breaks = 1:6) +
    labs(x = "", y = "rating", fill = "condition", col = "condition")
# ggdist
# https://mjskay.github.io/ggdist/articles/dotsinterval.html

set.seed(12345) # for reproducibility
library(ggdist)
p3 <- d3 %>%
  ggplot(aes(y = topic, x = importance, fill = topic)) +
  stat_slab(aes(thickness = stat(pdf*n)), scale = 0.7) +
  stat_dotsinterval(side = "bottom", scale = 0.7, slab_size = NA) +
  scale_fill_brewer(palette = "Set2")
p3

ggsave("../figures/rain_cloud_plot_importance.png", p3, dpi = 300, width = 13, height = 5, bg = "white")

p3 <- d3 %>%
  ggplot(aes(y = topic, x = newsworthiness, fill = topic)) +
  stat_slab(aes(thickness = stat(pdf*n)), scale = 0.7) +
  stat_dotsinterval(side = "bottom", scale = 0.7, slab_size = NA) +
  scale_fill_brewer(palette = "Set2")

ggsave("../figures/rain_cloud_plot_newsworthiness.png", p3, dpi = 300, width = 13, height = 5, bg = "white")

p3 <- d3 %>%
  ggplot(aes(y = topic, x = rating_combined, fill = topic)) +
  stat_slab(aes(thickness = stat(pdf*n)), scale = 0.7) +
  stat_dotsinterval(side = "bottom", scale = 0.7, slab_size = NA) +
  scale_fill_brewer(palette = "Set2")

ggsave("../figures/rain_cloud_plot_combined.png", p3, dpi = 300, width = 13, height = 5, bg = "white")


```















```{r}
d3[, condition := factor(condition, labels = c(-0.5, 0.5))]
d3$condition <- as.numeric(as.character(d3$condition))
d0_feed <- fread("../data/clean/data_feed.csv")
d0_feed <- mutate_if(d0_feed, is.integer, as.numeric) |> data.table()
glimpse(d0_feed)

d0_feed[, engage := likes_1 + shares_1 + read_later_1]
d0_feed[, engaged := 0]
d0_feed[likes_1 > 0 | shares_1 > 0 | read_later_1 > 0, engaged := 1]

# did people engage with first headline? yes
d0_feed[item_order == 0, .N, keyby = .(condition, engage, entity_id)]

# export/save as covariate
temp <- d0_feed[item_order == 0, .(user_id, engage_firstheadline = engage, condition)]
# fwrite(temp, "../data/clean/first_headline_engagement.csv")



# all relevant headlines (engaged or not)
df_split_dwell <- d0_feed[entity_set == "22apr25_willsmith", .(dwell = mean(dwell, na.rm = T), item_order = mean(item_order)), keyby = .(user_id, condition, chunk = ifelse(item_order < 15, "first15", "remaining"), entity_set)]
df_split_dwell

df_split_dwell_wide <- dcast(df_split_dwell, user_id + condition ~ chunk, value.var = c("dwell"))
df_split_dwell_wide[, dwell_diff := remaining - first15]
df_split_dwell_wide[, hist(dwell_diff, breaks = 50)]
# fwrite(df_split_dwell_wide, "../data/clean/dwell_split.csv")




# all relevant headlines (only not-engaged)
df_split_dwell <- d0_feed[entity_set == "22apr25_willsmith" & engaged == 0, .(dwell = mean(dwell, na.rm = T), item_order = mean(item_order)), keyby = .(user_id, condition, chunk = ifelse(item_order < 15, "first15", "remaining"), entity_set)]
df_split_dwell

df_split_dwell_wide <- dcast(df_split_dwell, user_id + condition ~ chunk, value.var = c("dwell"))
df_split_dwell_wide[, dwell_diff := remaining - first15]
df_split_dwell_wide[, hist(dwell_diff, breaks = 50)]
# fwrite(df_split_dwell_wide, "../data/clean/dwell_split_notengaged.csv")






temp2 <- left_join(d3[topic == "willsmith"], temp)
setDT(temp2)
glimpse(temp2)
temp3 <- copy(temp2)
temp2[, hist(engage_firstheadline)]
temp2[, engage_firstheadline := log(engage_firstheadline + 1)]
temp2[, engage_firstheadline := engage_firstheadline - mean(engage_firstheadline)]
temp2[, mean(engage_firstheadline)]
temp2[, hist(engage_firstheadline, breaks = 10)]


m1_imp <- lm(importance ~ condition, d3[topic == "willsmith"])
summaryh(m1_imp)
m1_imp <- lm(importance ~ condition + engage_firstheadline, temp2)
summaryh(m1_imp)

# compute bayes factor (via model comparison)
bfOnlyCondition = lmBF(importance ~ condition, data = temp2)
bfMainEffects = lmBF(importance ~ condition + engage_firstheadline, data = temp2)
bfInteraction = lmBF(importance ~ condition + engage_firstheadline + condition:engage_firstheadline, data = temp2)

bf = bfInteraction / bfMainEffects
bf
bf = bfInteraction / bfOnlyCondition
bf
bf = bfMainEffects / bfOnlyCondition
bf

m1_imp <- lm(newsworthiness ~ condition, d3[topic == "willsmith"])
summaryh(m1_imp)
m1_imp <- lm(newsworthiness ~ condition + engage_firstheadline, temp2)
summaryh(m1_imp)

# compute bayes factor (via model comparison)
bfOnlyCondition = lmBF(newsworthiness ~ condition, data = temp2)
bfMainEffects = lmBF(newsworthiness ~ condition + engage_firstheadline, data = temp2)
bfInteraction = lmBF(newsworthiness ~ condition + engage_firstheadline + condition:engage_firstheadline, data = temp2)

bf = bfInteraction / bfMainEffects
bf
bf = bfInteraction / bfOnlyCondition
bf
bf = bfMainEffects / bfOnlyCondition
bf

# split dwell analysis
tempSplitDwell_df <- fread("../data/clean/dwell_split.csv")
d3_tempSplitDwell <- left_join(d3, tempSplitDwell_df)
correlation::cor_test(d3_tempSplitDwell[topic=="willsmith"], "importance", "dwell_diff")
correlation::cor_test(d3_tempSplitDwell[topic=="willsmith"], "newsworthiness", "dwell_diff")


correlation::cor_test(d3_tempSplitDwell[topic=="willsmith"], "importance", "dwell_diff", method = "kendall")
correlation::cor_test(d3_tempSplitDwell[topic=="willsmith"], "newsworthiness", "dwell_diff", method = "kendall")


tempSplitDwell_df <- fread("../data/clean/dwell_split_notengaged.csv")
d3_tempSplitDwell <- left_join(d3, tempSplitDwell_df)
correlation::cor_test(d3_tempSplitDwell[topic=="willsmith"], "importance", "dwell_diff")
correlation::cor_test(d3_tempSplitDwell[topic=="willsmith"], "newsworthiness", "dwell_diff")


correlation::cor_test(d3_tempSplitDwell[topic=="willsmith"], "importance", "dwell_diff", method = "kendall")
correlation::cor_test(d3_tempSplitDwell[topic=="willsmith"], "newsworthiness", "dwell_diff", method = "kendall")
```







```{r b0 b1 across time analysis}
glimpse(d0_feed)
d0_feed <- d0_feed[attention == 1 & ipblock == 0]
d0_feed_ws <- d0_feed[entity_set == "22apr25_willsmith"]
d0_feed_cc <- d0_feed[entity_set == "22apr25_willsmith"]



# create beginning mid end for users
d0_feed_cc_top <- d0_feed_cc
d0_feed_cc_top$item_order <- abs(d0_feed_cc_top$item_order - 0.0)
d0_feed_cc_top <- d0_feed_cc_top[with(d0_feed_cc_top, order(user_id, item_order)), ]
d0_feed_cc_top <- d0_feed_cc_top[, head(.SD, 5), by=user_id]
d0_feed_cc_top <- d0_feed_cc_top[ , if (.N == 5L) .SD, by = user_id]
d0_feed_cc_top <- d0_feed_cc_top[,lapply(.SD,mean,na.rm=TRUE),by=user_id,.SDcols=c("dwell", "engage")]
d0_feed_cc_top$timepoint <- 1

d0_feed_cc_mid <- d0_feed_cc
d0_feed_cc_mid$item_order <- abs(d0_feed_cc_mid$item_order - 50.0)
d0_feed_cc_mid <- d0_feed_cc_mid[with(d0_feed_cc_mid, order(user_id, item_order)), ]
d0_feed_cc_mid <- d0_feed_cc_mid[, head(.SD, 5), by=user_id]
d0_feed_cc_mid <- d0_feed_cc_mid[ , if (.N == 5L) .SD, by = user_id]
d0_feed_cc_mid <- d0_feed_cc_mid[,lapply(.SD,mean,na.rm=TRUE),by=user_id,.SDcols=c("dwell", "engage")]
d0_feed_cc_mid$timepoint <- 2

d0_feed_cc_end <- d0_feed_cc
d0_feed_cc_end$item_order <- abs(d0_feed_cc_end$item_order - 99.0)
d0_feed_cc_end <- d0_feed_cc_end[with(d0_feed_cc_end, order(user_id, item_order)), ]
d0_feed_cc_end <- d0_feed_cc_end[, head(.SD, 5), by=user_id]
d0_feed_cc_end <- d0_feed_cc_end[ , if (.N == 5L) .SD, by = user_id]
d0_feed_cc_end <- d0_feed_cc_end[,lapply(.SD,mean,na.rm=TRUE),by=user_id,.SDcols=c("dwell", "engage")]
d0_feed_cc_end$timepoint <- 3

d0_feed_cc_timed <- rbind(d0_feed_cc_top, d0_feed_cc_mid, d0_feed_cc_end)
d3_feed_cc_timed <- left_join(d3, d0_feed_cc_timed) |> data.table()


d3_feed_cc_timed <- dcast(d3_feed_cc_timed[topic=="willsmith" & condition == 0.5], user_id + condition + topic + willsmith_perc + importance + newsworthiness + rating_combined + willsmith_percC ~ timepoint, value.var = c("dwell", "engage"))

summaryh(lm(importance ~ dwell_1 * dwell_2 * dwell_3, d3_feed_cc_timed[topic=="willsmith"]))
summaryh(lm(newsworthiness ~ dwell_1 * dwell_2 * dwell_3, d3_feed_cc_timed[topic=="willsmith"]))
summaryh(lm(importance ~ engage_1 * engage_2 * engage_3, d3_feed_cc_timed[topic=="willsmith"]))
summaryh(lm(newsworthiness ~ engage_1 * engage_2 * engage_3, d3_feed_cc_timed[topic=="willsmith"]))

plot_cme(lm(importance ~ dwell_1 * dwell_2 * dwell_3, d3_feed_cc_timed[topic=="willsmith"]), effect = "dwell_2", condition = "dwell_3")
plot_cme(lm(newsworthiness ~ dwell_1 * dwell_2 * dwell_3, d3_feed_cc_timed[topic=="willsmith"]), effect = "dwell_2", condition = "dwell_3")


# dwell over time
library(brms)
include <- d0_feed_cc[condition == 0.5 & engaged == 0, .N, user_id][, user_id]
tempdat <- d0_feed_cc[user_id %in% include]
# tempdat[, item_order := (item_order - mean(item_order, na.rm = T)) / sd(item_order, na.rm = T), user_id]
tempdat[, dwell := log(dwell + 1)]

mod <- brm(dwell ~ item_order + (item_order | user_id), data = tempdat[user_id %in% include], cores = 4, iter = 20000)
mod
betas <- coef(mod)
b0 <- betas$user_id[,,'Intercept'][, 'Estimate']
b1 <- betas$user_id[,,'item_order'][, 'Estimate']
dfbetas <- data.table(user_id = names(b0), b0, b1)
fwrite(dfbetas, "../data/clean/coef_dwell-itemorder.csv")

# change outcome from dwell to engage!
include <- d0_feed_cc[condition == 0.5, .N, user_id][, user_id]
tempdat <- d0_feed_cc[user_id %in% include]
# tempdat[, item_order := (item_order - mean(item_order, na.rm = T)) / sd(item_order, na.rm = T), user_id]
mod <- brm(engage ~ item_order + (item_order | user_id), data = tempdat[user_id %in% include], cores = 4, iter = 20000)
mod
betas <- coef(mod)
b0 <- betas$user_id[,,'Intercept'][, 'Estimate']
b1 <- betas$user_id[,,'item_order'][, 'Estimate']
dfbetas <- data.table(user_id = names(b0), b0, b1)
fwrite(dfbetas, "../data/clean/coef_engage-itemorder.csv")


# correlate b1 with importance ratings
b1_dwell_df <- fread("../data/clean/coef_dwell-itemorder.csv")
b1_engage_df <- fread("../data/clean/coef_engage-itemorder.csv")
d3_b1_dwell <- left_join(d3, b1_dwell_df) |> data.table()
d3_b1_engage <- left_join(d3, b1_engage_df) |> data.table()





d0_feed_cc_agg <- d0_feed_cc[,lapply(.SD,mean,na.rm=TRUE),by=user_id,.SDcols=c("dwell")]
d3_b1_dwell_agg <- left_join(d0_feed_cc_agg, d3_b1_engage[topic=="willsmith"]) |> data.table()
d3_b1_dwell_agg[, b0c := b0 - mean(b0, na.rm = T)]
d3_b1_dwell_agg[, b1c := b1 - mean(b1, na.rm = T)]
d3_b1_dwell_agg[, dwellc := dwell - mean(dwell, na.rm = T)]
d3_b1_dwell_agg[, sqrtdwellc := log(dwell+1) - mean(log(dwell+1), na.rm = T)]

summaryh(lm(importance ~ dwellc * b0c, d3_b1_dwell_agg[topic=="willsmith"]))
summaryh(lm(newsworthiness ~ dwellc * b0c, d3_b1_dwell_agg[topic=="willsmith"]))

summaryh(lm(importance ~ sqrtdwellc * b0c, d3_b1_dwell_agg[topic=="willsmith"]))
summaryh(lm(newsworthiness ~ sqrtdwellc * b0c, d3_b1_dwell_agg[topic=="willsmith"]))
hist((d3_b1_dwell_agg$sqrtdwellc))
hist((d3_b1_dwell_agg$dwellc))




d0_feed_cc_agg <- d0_feed_cc[,lapply(.SD,sum,na.rm=TRUE),by=user_id,.SDcols=c("engage")]
d3_b1_engage_agg <- left_join(d0_feed_cc_agg, d3_b1_engage[topic=="willsmith"]) |> data.table()
d3_b1_engage_agg[, b0c := b0 - mean(b0, na.rm = T)]
d3_b1_engage_agg[, b1c := b1 - mean(b1, na.rm = T)]
d3_b1_engage_agg[, engagec := engage - mean(engage, na.rm = T)]
d3_b1_engage_agg[, sqrtengagec := log(engage+1) - mean(log(engage+1), na.rm = T)]

summaryh(lm(importance ~ engagec * b0c, d3_b1_engage_agg[topic=="willsmith"]))
summaryh(lm(newsworthiness ~ engagec * b0c, d3_b1_engage_agg[topic=="willsmith"]))

summaryh(lm(importance ~ sqrtengagec * b0c, d3_b1_engage_agg[topic=="willsmith"]))
summaryh(lm(newsworthiness ~ sqrtengagec * b0c, d3_b1_engage_agg[topic=="willsmith"]))
hist((d3_b1_engage_agg$sqrtengagec), breaks = 60)
hist((d3_b1_engage_agg$engagec), breaks=50)






# dwell
correlation::cor_test(d3_b1_dwell[topic=="willsmith"], "importance", "b1")
correlation::cor_test(d3_b1_dwell[topic=="willsmith"], "newsworthiness", "b1")
correlation::cor_test(d3_b1_dwell[topic=="willsmith"], "importance", "b1", method = "spearman")
correlation::cor_test(d3_b1_dwell[topic=="willsmith"], "newsworthiness", "b1", method = "spearman")

d3_b1_dwell[, b0c := b0 - mean(b0, na.rm = T)]
d3_b1_dwell[, b1c := b1 - mean(b1, na.rm = T)]
summaryh(lm(importance ~ b0c * b1c, d3_b1_dwell[topic=="willsmith"]))
summaryh(lm(newsworthiness ~ b0c * b1c, d3_b1_dwell[topic=="willsmith"]))

# engage
correlation::cor_test(d3_b1_engage[topic=="willsmith"], "importance", "b1")
correlation::cor_test(d3_b1_engage[topic=="willsmith"], "newsworthiness", "b1")
correlation::cor_test(d3_b1_engage[topic=="willsmith"], "importance", "b1", method = "spearman")
correlation::cor_test(d3_b1_engage[topic=="willsmith"], "newsworthiness", "b1", method = "spearman")

d3_b1_engage[, b0c := b0 - mean(b0, na.rm = T)]
d3_b1_engage[, b1c := b1 - mean(b1, na.rm = T)]
summaryh(lm(importance ~ b0c * b1c, d3_b1_engage[topic=="willsmith"]))
summaryh(lm(newsworthiness ~ b0c * b1c, d3_b1_engage[topic=="willsmith"]))


ggplot(d3_b1_engage[topic=="willsmith"], aes(b0, importance)) + geom_point()
ggplot(d3_b1_engage[topic=="willsmith"], aes(b1, importance)) + geom_point()
```



















# other




```{r}
p1 <- ggplot(d0_feed_ws, aes(item_order, dwell)) +
    geom_smooth(method = 'lm') +
    stat_summary(fun = mean, geom = 'point', shape = 95, size = 6, position = position_dodge(1)) +
    stat_summary(fun.data = mean_cl_normal, geom = 'errorbar', width = 0, size = 0.8, position = position_dodge(1))

p2 <- ggplot(d0_feed_ws, aes(item_order, likes_1)) +
    geom_smooth(method = 'lm') +
    stat_summary(fun = mean, geom = 'point', shape = 95, size = 6, position = position_dodge(1)) +
    stat_summary(fun.data = mean_cl_normal, geom = 'errorbar', width = 0, size = 0.8, position = position_dodge(1))

p3 <- ggplot(d0_feed_ws, aes(item_order, shares_1)) +
    geom_smooth(method = 'lm') +
    stat_summary(fun = mean, geom = 'point', shape = 95, size = 6, position = position_dodge(1)) +
    stat_summary(fun.data = mean_cl_normal, geom = 'errorbar', width = 0, size = 0.8, position = position_dodge(1))

p4 <- ggplot(d0_feed_ws, aes(item_order, read_later_1)) +
    geom_smooth(method = 'lm') +
    stat_summary(fun = mean, geom = 'point', shape = 95, size = 6, position = position_dodge(1)) +
    stat_summary(fun.data = mean_cl_normal, geom = 'errorbar', width = 0, size = 0.8, position = position_dodge(1))

p1 / p2 / p3 / p4



include <- d0_feed_ws[condition == 0.5 & engaged == 0, .N, user_id][N > 5, user_id]
coefs <- d0_feed_ws[condition == 0.5 & user_id %in% include, .(b1 = coef(lm(ldwell ~ item_order))[2]), user_id]
coefs

feed_avg <- d0_feed_ws[condition == 0.5, .(like = mean(likes_1, na.rm = T),
            share = mean(shares_1, na.rm = T),
            read = mean(read_later_1, na.rm = T),
            ldwell = mean(ldwell, na.rm = T),
            n_dwell = mean(n_dwells, na.rm = T),
            engage = mean(engage, na.rm = T)),
           user_id]
feed_avg[order(-engage)]

# exclude extreme engagers
feed_avg <- feed_avg[share < 1.0][like < 1][read < 1]

dwell_engage0 <- d0_feed_ws[engaged == 0, .(ldwell_engage0 = mean(ldwell, na.rm = T)), user_id]

d5 <- left_join(d3, feed_avg) |> left_join(coefs) |> left_join(dwell_engage0) |>  data.table()
d5

library(hausekeep)
d5[topic == "willsmith" & condition == 0.5, hist(log(like + 1))]
d5[topic == "willsmith" & condition == 0.5, hist(like)]
summaryh(lm(newsworthiness ~ log(like + 1), d5[topic == "willsmith" & condition == 0.5]))  # ya
summaryh(lm(newsworthiness ~ like, d5[topic == "willsmith" & condition == 0.5]))  # ya
summaryh(lm(newsworthiness ~ log(read + 1), d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(newsworthiness ~ share, d5[topic == "willsmith" & condition == 0.5])) # works well if we exclude outlier
summaryh(lm(newsworthiness ~ log(share + 1), d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(newsworthiness ~ ldwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(newsworthiness ~ ldwell_engage0, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(newsworthiness ~ n_dwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(newsworthiness ~ engage, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(newsworthiness ~ b1, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(newsworthiness ~ like + read + share + ldwell + n_dwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(newsworthiness ~ like + read + ldwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(newsworthiness ~ like + read + ldwell + willsmith_perc, d5[topic == "willsmith" & condition == 0.5]))

summaryh(lm(importance ~ like, d5[topic == "willsmith" & condition == 0.5]))  #
summaryh(lm(importance ~ log(like + 1), d5[topic == "willsmith" & condition == 0.5]))  #
summaryh(lm(importance ~ read, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(importance ~ log(read + 1), d5[topic == "willsmith" & condition == 0.5]))  #
summaryh(lm(importance ~ share, d5[topic == "willsmith" & condition == 0.5])) # 
summaryh(lm(importance ~ log(share + 1), d5[topic == "willsmith" & condition == 0.5]))  #
summaryh(lm(importance ~ ldwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(importance ~ ldwell_engage0, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(importance ~ n_dwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(importance ~ engage, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(importance ~ b1, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(importance ~ like + read + share + ldwell + n_dwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(importance ~ like + read + ldwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(importance ~ like + read + ldwell + willsmith_perc, d5[topic == "willsmith" & condition == 0.5]))

summaryh(lm(rating_combined ~ like, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(rating_combined ~ read, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(rating_combined ~ share, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(rating_combined ~ ldwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(rating_combined ~ ldwell_engage0, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(rating_combined ~ n_dwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(rating_combined ~ engage, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(rating_combined ~ b1, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(rating_combined ~ like + read + share + ldwell + n_dwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(rating_combined ~ like + read + ldwell + willsmith_perc, d5[topic == "willsmith" & condition == 0.5]))

summaryh(lm(willsmith_perc ~ like, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(willsmith_perc ~ read, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(willsmith_perc ~ share, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(willsmith_perc ~ ldwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(willsmith_perc ~ ldwell_engage0, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(willsmith_perc ~ n_dwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(willsmith_perc ~ engage, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(willsmith_perc ~ b1, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(willsmith_perc ~ like + read + share + ldwell + n_dwell, d5[topic == "willsmith" & condition == 0.5]))
summaryh(lm(willsmith_perc ~ like + read + ldwell, d5[topic == "willsmith" & condition == 0.5]))

p1 <- plot(correlation::cor_test(d5[condition == 0.5 & topic == "willsmith"], "share", "importance")) +
    scale_y_continuous(limits = c(1, 6), breaks = 1:6)
p2 <- plot(correlation::cor_test(d5[condition == 0.5 & topic == "willsmith"], "like", "importance")) +
    scale_y_continuous(limits = c(1, 6), breaks = 1:6)
p1 + p2

library(fixest)
feols(ldwell ~ btn_likes | user_id, d0_feed_ws[engaged == 0])
feols(ldwell ~ btn_shares | user_id, d0_feed_ws[engaged == 0])

feols(ldwell ~ btn_likes | user_id, d0_feed[engaged == 0])
feols(ldwell ~ btn_shares | user_id, d0_feed[engaged == 0])



```

